#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dify Webhook æŠ¥è­¦å‘é€æ¨¡å—
ç”¨äºå°†å…³é”®é”™è¯¯å’ŒæˆåŠŸäº‹ä»¶å‘é€åˆ° Dify å·¥ä½œæµè¿›è¡Œæ—¥å¿—è®°å½•
"""

import requests
import json
import traceback
import sys
import logging
from datetime import datetime
from typing import Optional
import threading

logger = logging.getLogger(__name__)

# --- é…ç½®åŒºåŸŸ (ä» config.py å¯¼å…¥) ---
try:
    from config import DIFY_CONFIG
    DIFY_API_KEY = DIFY_CONFIG.get('api_key', '')
    DIFY_BASE_URL = DIFY_CONFIG.get('base_url', 'http://localhost:5001')
    DIFY_WORKFLOW_ID = DIFY_CONFIG.get('workflow_id', '')
    DIFY_USER_ID = DIFY_CONFIG.get('user_id', '')
except (ImportError, AttributeError) as e:
    # å¦‚æœ config.py ä¸­æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
    DIFY_API_KEY = ""
    DIFY_BASE_URL = "http://localhost:5001"
    DIFY_WORKFLOW_ID = ""
    DIFY_USER_ID = ""


def _send_webhook_request(payload: dict):
    """
    å®é™…å‘é€ HTTP POST è¯·æ±‚çš„å†…éƒ¨å‡½æ•°
    
    Args:
        payload: è¯·æ±‚ä½“æ•°æ®
    """
    if not DIFY_API_KEY:
        logger.warning("[Dify] âš ï¸ API Key æœªé…ç½®ï¼Œè·³è¿‡æŠ¥è­¦å‘é€")
        return
    
    # å¦‚æœæŒ‡å®šäº† workflow_idï¼Œä½¿ç”¨æŒ‡å®šç‰ˆæœ¬ï¼›å¦åˆ™ä½¿ç”¨å·²å‘å¸ƒçš„å·¥ä½œæµ
    if DIFY_WORKFLOW_ID:
        url = f"{DIFY_BASE_URL}/v1/workflows/{DIFY_WORKFLOW_ID}/run"
    else:
        url = f"{DIFY_BASE_URL}/v1/workflows/run"
        logger.info("[Dify] ä½¿ç”¨å·²å‘å¸ƒçš„å·¥ä½œæµç‰ˆæœ¬ï¼ˆæœªæŒ‡å®š workflow_idï¼‰")
    headers = {
        "Authorization": f"Bearer {DIFY_API_KEY}",
        "Content-Type": "application/json"
    }
    
    try:
        logger.info(f"[Dify] æ­£åœ¨å‘é€äº‹ä»¶åˆ° {url}")
        logger.info(f"[Dify] äº‹ä»¶ç±»å‹: {payload.get('inputs', {}).get('event_type', 'unknown')}")
        logger.debug(f"[Dify] è¯·æ±‚ä½“: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        # è®¾ç½®çŸ­è¶…æ—¶ï¼Œé˜²æ­¢ Dify å“åº”æ…¢æ—¶å¡ä½ä¸»ä¸šåŠ¡çº¿ç¨‹
        response = requests.post(url, headers=headers, json=payload, timeout=5)  # å¢åŠ åˆ°5ç§’è¶…æ—¶
        if response.status_code not in [200, 201]:
            # è®°å½•åˆ°æœ¬åœ°æ—¥å¿—ä½œä¸ºå›é€€
            logger.warning(f"[Dify] æŠ¥è­¦å‘é€å¤±è´¥: HTTP {response.status_code}, {response.text}")
        else:
            logger.info(f"[Dify] âœ… æŠ¥è­¦å‘é€æˆåŠŸ: {payload.get('inputs', {}).get('level', 'UNKNOWN')} - {payload.get('inputs', {}).get('message', '')}")
            try:
                result = response.json()
                logger.debug(f"[Dify] å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
            except:
                logger.debug(f"[Dify] å“åº”æ–‡æœ¬: {response.text[:200]}")
    except requests.exceptions.Timeout:
        logger.warning(f"[Dify] âš ï¸ æŠ¥è­¦å‘é€è¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼ŒURL: {url}")
    except requests.exceptions.ConnectionError as e:
        logger.warning(f"[Dify] âš ï¸ æ— æ³•è¿æ¥åˆ° Dify æœåŠ¡: {e}, URL: {url}")
    except Exception as e:
        logger.warning(f"[Dify] âš ï¸ Webhook è¿æ¥é”™è¯¯: {e}, URL: {url}")
        import traceback
        logger.debug(f"[Dify] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")


def send_alarm_webhook(task_id: str, module: str, level: str, message: str, detail: str = ""):
    """
    å‘é€ç»“æ„åŒ–çš„æŠ¥è­¦ Webhook åˆ° Difyï¼ˆå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ log_eventï¼‰
    
    Args:
        task_id: ä»»åŠ¡çš„å”¯ä¸€ ID (UUID)
        module: è§¦å‘æŠ¥è­¦çš„æ¨¡å— (å¦‚: ASR_Core, PipelineService)
        level: æŠ¥è­¦çº§åˆ«ï¼Œå¿…é¡»æ˜¯ ERROR æˆ– SUCCESS
        message: ç®€çŸ­çš„æŠ¥è­¦ä¿¡æ¯
        detail: å®Œæ•´çš„é”™è¯¯å †æ ˆæˆ–å…³é”®ç»“æœ JSONï¼ˆå¯é€‰ï¼‰
    """
    # å‘åå…¼å®¹ï¼šè°ƒç”¨æ–°çš„ log_event å‡½æ•°
    log_event(
        task_id=task_id,
        event_type="transcribe",  # é»˜è®¤äº‹ä»¶ç±»å‹
        module=module,
        level=level,
        message=message,
        detail=detail
    )


def log_event(
    task_id: str,
    event_type: str,
    module: str,
    level: str,
    message: str,
    detail: str = "",
    file_id: str = "",
    filename: str = "",
    file_size: int = 0
):
    """
    é€šç”¨äº‹ä»¶æ—¥å¿—å‡½æ•° - å‘é€ç»“æ„åŒ–äº‹ä»¶åˆ° Dify
    
    Args:
        task_id: ä»»åŠ¡çš„å”¯ä¸€ ID (UUID)
        event_type: äº‹ä»¶ç±»å‹ (upload, transcribe, download, delete, clear_history, error)
        module: è§¦å‘äº‹ä»¶çš„æ¨¡å— (å¦‚: VoiceGateway, PipelineService)
        level: äº‹ä»¶çº§åˆ« (SUCCESS, ERROR)
        message: ç®€çŸ­çš„äº‹ä»¶æè¿°
        detail: è¯¦ç»†ä¿¡æ¯ï¼ˆJSONå­—ç¬¦ä¸²æˆ–æ™®é€šæ–‡æœ¬ï¼‰
        file_id: æ–‡ä»¶IDï¼ˆå¯é€‰ï¼‰
        filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        file_size: æ–‡ä»¶å¤§å°ï¼Œå•ä½å­—èŠ‚ï¼ˆå¯é€‰ï¼‰
    """
    if level not in ["ERROR", "SUCCESS"]:
        logger.warning(f"[Dify] è·³è¿‡éå…³é”®äº‹ä»¶: {level}")
        return
    
    # åªä¿ç•™è½¬å†™äº‹ä»¶å’Œé”™è¯¯äº‹ä»¶çš„æ—¥å¿—ï¼Œå…¶ä»–äº‹ä»¶ç±»å‹ä¸å‘é€åˆ° Dify
    if event_type not in ["transcribe", "error"]:
        logger.debug(f"[Dify] è·³è¿‡éè½¬å†™äº‹ä»¶: {event_type} - {message}")
        return
    
    if not DIFY_API_KEY:
        logger.warning(f"[Dify] âš ï¸ API Key æœªé…ç½®ï¼Œè·³è¿‡äº‹ä»¶æ—¥å¿—")
        return
    
    # workflow_id æ˜¯å¯é€‰çš„ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨å·²å‘å¸ƒçš„å·¥ä½œæµ
    if not DIFY_WORKFLOW_ID:
        logger.info("[Dify] æœªæŒ‡å®š workflow_idï¼Œå°†ä½¿ç”¨å·²å‘å¸ƒçš„å·¥ä½œæµç‰ˆæœ¬")
    
    logger.info(f"[Dify] ğŸ“¤ å‡†å¤‡å‘é€äº‹ä»¶æ—¥å¿—: event_type={event_type}, level={level}, module={module}, message={message}, file_id={file_id}, filename={filename}")
    
    # æ„å»º detailï¼Œå¦‚æœæä¾›äº†é¢å¤–ä¿¡æ¯ï¼Œåˆå¹¶åˆ° detail ä¸­
    detail_obj = {}
    if detail:
        try:
            # å°è¯•è§£æä¸º JSON
            detail_obj = json.loads(detail)
            if not isinstance(detail_obj, dict):
                detail_obj = {"raw": detail}
        except (json.JSONDecodeError, TypeError):
            # å¦‚æœä¸æ˜¯ JSONï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬
            detail_obj = {"raw": detail}
    
    # æ·»åŠ æ–‡ä»¶ä¿¡æ¯åˆ° detail
    if file_id:
        detail_obj["file_id"] = file_id
    if filename:
        detail_obj["filename"] = filename
    if file_size > 0:
        detail_obj["file_size"] = file_size
    
    # å°† detail_obj è½¬æ¢å› JSON å­—ç¬¦ä¸²
    detail_str = json.dumps(detail_obj, ensure_ascii=False) if detail_obj else ""
    
    payload = {
        "inputs": {
            "task_id": str(task_id),
            "level": level,
            "module": module,
            "message": message,
            "detail": detail_str,
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,  # æ–°å¢ï¼šäº‹ä»¶ç±»å‹
            "file_id": str(file_id) if file_id else str(task_id),  # æ–°å¢ï¼šæ–‡ä»¶ID
            "filename": str(filename) if filename else "",  # æ–°å¢ï¼šæ–‡ä»¶å
            "file_size": int(file_size) if file_size > 0 else 0  # æ–°å¢ï¼šæ–‡ä»¶å¤§å°
        },
        "response_mode": "blocking",  # ä¿è¯æ—¥å¿—å‘é€çš„å¯é æ€§
        "user": DIFY_USER_ID if DIFY_USER_ID else f"event_{task_id}"
    }
    
    # ä½¿ç”¨å¼‚æ­¥çº¿ç¨‹å‘é€ (æ¨è!)ï¼Œé˜²æ­¢ Webhook å»¶è¿Ÿå½±å“ä¸»ä¸šåŠ¡æµ
    threading.Thread(
        target=_send_webhook_request,
        args=(payload,),
        daemon=True,
        name=f"DifyEvent-{event_type}-{task_id[:8]}"
    ).start()


def log_error_alarm(task_id: str, module: str, message: str, exception: Optional[Exception] = None):
    """
    ä¸“é—¨ç”¨äºæ•è·å¼‚å¸¸å¹¶å‘é€ ERROR æŠ¥è­¦çš„è¾…åŠ©å‡½æ•°
    
    Args:
        task_id: ä»»åŠ¡çš„å”¯ä¸€ ID
        module: è§¦å‘æŠ¥è­¦çš„æ¨¡å—
        message: é”™è¯¯æ¶ˆæ¯
        exception: å¼‚å¸¸å¯¹è±¡ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›ä¼šè‡ªåŠ¨æå–å †æ ˆä¿¡æ¯
    """
    # è‡ªåŠ¨è·å–å®Œæ•´çš„å †æ ˆä¿¡æ¯
    if exception:
        try:
            error_stack = ''.join(traceback.format_exception(type(exception), exception, exception.__traceback__))
        except:
            error_stack = traceback.format_exc()
    else:
        error_stack = traceback.format_exc()
    
    # å¢å¼ºé”™è¯¯æ¶ˆæ¯ï¼šå¦‚æœæ˜¯ç‰¹å®šç±»å‹çš„é”™è¯¯ï¼Œæ·»åŠ æ›´è¯¦ç»†çš„æ¨¡å—ä¿¡æ¯
    enhanced_module = module
    if exception:
        error_str = str(exception)
        if "CUDA" in error_str or "GPU" in error_str or "OOM" in error_str:
            enhanced_module = "GPU_OOM"
        elif "timeout" in error_str.lower():
            enhanced_module = f"{module}_Timeout"
        elif "connection" in error_str.lower():
            enhanced_module = f"{module}_Connection"
    
    # ä½¿ç”¨æ–°çš„ log_event å‡½æ•°
    log_event(
        task_id=task_id,
        event_type="error",
        module=enhanced_module,
        level="ERROR",
        message=message,
        detail=error_stack
    )


def log_success_alarm(task_id: str, module: str, message: str, detail: str = "", file_size: int = 0):
    """
    å‘é€ SUCCESS æŠ¥è­¦çš„è¾…åŠ©å‡½æ•°ï¼ˆè½¬å†™æˆåŠŸä¸“ç”¨ï¼‰
    
    Args:
        task_id: ä»»åŠ¡çš„å”¯ä¸€ ID
        module: è§¦å‘æŠ¥è­¦çš„æ¨¡å—
        message: æˆåŠŸæ¶ˆæ¯
        detail: è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚è½¬å†™å­—æ•°ã€è€—æ—¶ç­‰ï¼ŒJSONæ ¼å¼ï¼‰
        file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼Œå¯é€‰ï¼‰
    """
    # ä» detail ä¸­æå– file_id å’Œ filenameï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    file_id = task_id
    filename = ""
    
    if detail:
        try:
            detail_obj = json.loads(detail)
            if isinstance(detail_obj, dict):
                file_id = detail_obj.get('file_id', task_id)
                filename = detail_obj.get('filename', '')
        except:
            pass
    
    log_event(
        task_id=task_id,
        event_type="transcribe",
        module=module,
        level="SUCCESS",
        message=message,
        detail=detail,
        file_id=file_id,
        filename=filename,
        file_size=file_size
    )


# ==================== æ–°å¢ï¼šç‰¹å®šäº‹ä»¶ç±»å‹çš„æ—¥å¿—å‡½æ•° ====================

def log_upload_event(file_id: str, filename: str, file_size: int, level: str, error: Optional[Exception] = None):
    """
    è®°å½•æ–‡ä»¶ä¸Šä¼ äº‹ä»¶
    
    Args:
        file_id: æ–‡ä»¶ID
        filename: æ–‡ä»¶å
        file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        level: SUCCESS æˆ– ERROR
        error: é”™è¯¯å¼‚å¸¸ï¼ˆå¯é€‰ï¼‰
    """
    if level == "SUCCESS":
        message = f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {filename}"
        detail = ""
    else:
        message = f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {filename}"
        if error:
            detail = ''.join(traceback.format_exception(type(error), error, error.__traceback__))
        else:
            detail = "æœªçŸ¥é”™è¯¯"
    
    log_event(
        task_id=file_id,
        event_type="upload",
        module="VoiceGateway",
        level=level,
        message=message,
        detail=detail,
        file_id=file_id,
        filename=filename,
        file_size=file_size
    )


def log_download_event(file_id: str, filename: str, level: str, error: Optional[Exception] = None):
    """
    è®°å½•æ–‡ä»¶ä¸‹è½½äº‹ä»¶
    
    Args:
        file_id: æ–‡ä»¶ID
        filename: æ–‡ä»¶å
        level: SUCCESS æˆ– ERROR
        error: é”™è¯¯å¼‚å¸¸ï¼ˆå¯é€‰ï¼‰
    """
    if level == "SUCCESS":
        message = f"æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename}"
        detail = ""
    else:
        message = f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {filename}"
        if error:
            detail = ''.join(traceback.format_exception(type(error), error, error.__traceback__))
        else:
            detail = "æœªçŸ¥é”™è¯¯"
    
    log_event(
        task_id=file_id,
        event_type="download",
        module="VoiceGateway",
        level=level,
        message=message,
        detail=detail,
        file_id=file_id,
        filename=filename
    )


def log_delete_event(file_id: str, filename: str, level: str, error: Optional[Exception] = None, was_stopped: bool = False):
    """
    è®°å½•æ–‡ä»¶åˆ é™¤äº‹ä»¶
    
    Args:
        file_id: æ–‡ä»¶ID
        filename: æ–‡ä»¶å
        level: SUCCESS æˆ– ERROR
        error: é”™è¯¯å¼‚å¸¸ï¼ˆå¯é€‰ï¼‰
        was_stopped: æ˜¯å¦æ˜¯è¢«åœæ­¢çš„è½¬å†™æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    """
    if level == "SUCCESS":
        message = f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {filename}"
        detail_obj = {}
        if was_stopped:
            detail_obj["was_stopped"] = True
        detail = json.dumps(detail_obj, ensure_ascii=False) if detail_obj else ""
    else:
        message = f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {filename}"
        if error:
            error_stack = ''.join(traceback.format_exception(type(error), error, error.__traceback__))
            detail_obj = {"error": error_stack}
            if was_stopped:
                detail_obj["was_stopped"] = True
            detail = json.dumps(detail_obj, ensure_ascii=False)
        else:
            detail_obj = {"error": "æœªçŸ¥é”™è¯¯"}
            if was_stopped:
                detail_obj["was_stopped"] = True
            detail = json.dumps(detail_obj, ensure_ascii=False)
    
    log_event(
        task_id=file_id,
        event_type="delete",
        module="VoiceGateway",
        level=level,
        message=message,
        detail=detail,
        file_id=file_id,
        filename=filename
    )


def log_clear_history_event(
    level: str, 
    deleted_records: int = 0,
    deleted_audio_files: int = 0,
    deleted_transcript_files: int = 0,
    error: Optional[Exception] = None
):
    """
    è®°å½•æ¸…ç©ºå†å²è®°å½•äº‹ä»¶
    
    Args:
        level: SUCCESS æˆ– ERROR
        deleted_records: åˆ é™¤çš„å†å²è®°å½•æ¡æ•°
        deleted_audio_files: åˆ é™¤çš„éŸ³é¢‘æ–‡ä»¶æ•°
        deleted_transcript_files: åˆ é™¤çš„è½¬å†™æ–‡æ¡£æ•°
        error: é”™è¯¯å¼‚å¸¸ï¼ˆå¯é€‰ï¼‰
    """
    import uuid
    task_id = str(uuid.uuid4())
    
    if level == "SUCCESS":
        # æ„å»ºè¯¦ç»†çš„æ¶ˆæ¯
        parts = []
        if deleted_records > 0:
            parts.append(f"{deleted_records} æ¡å†å²è®°å½•")
        if deleted_audio_files > 0:
            parts.append(f"{deleted_audio_files} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        if deleted_transcript_files > 0:
            parts.append(f"{deleted_transcript_files} ä¸ªè½¬å†™æ–‡æ¡£")
        
        if parts:
            message = f"æ¸…ç©ºå†å²è®°å½•æˆåŠŸ: åˆ é™¤äº† {', '.join(parts)}"
        else:
            message = "æ¸…ç©ºå†å²è®°å½•æˆåŠŸ: æ²¡æœ‰éœ€è¦åˆ é™¤çš„å†…å®¹"
        
        detail = json.dumps({
            "deleted_records": deleted_records,
            "deleted_audio_files": deleted_audio_files,
            "deleted_transcript_files": deleted_transcript_files
        }, ensure_ascii=False)
    else:
        message = f"æ¸…ç©ºå†å²è®°å½•å¤±è´¥"
        if error:
            detail = ''.join(traceback.format_exception(type(error), error, error.__traceback__))
        else:
            detail = "æœªçŸ¥é”™è¯¯"
    
    log_event(
        task_id=task_id,
        event_type="clear_history",
        module="VoiceGateway",
        level=level,
        message=message,
        detail=detail
    )


def log_stop_transcription_event(file_id: str, filename: str, level: str, error: Optional[Exception] = None, progress: int = 0):
    """
    è®°å½•åœæ­¢è½¬å†™äº‹ä»¶
    
    Args:
        file_id: æ–‡ä»¶ID
        filename: æ–‡ä»¶å
        level: SUCCESS æˆ– ERROR
        error: é”™è¯¯å¼‚å¸¸ï¼ˆå¯é€‰ï¼‰
        progress: åœæ­¢æ—¶çš„è¿›åº¦ï¼ˆ0-100ï¼Œå¯é€‰ï¼‰
    """
    if level == "SUCCESS":
        message = f"è½¬å†™å·²åœæ­¢: {filename}"
        detail_obj = {
            "file_id": file_id,
            "filename": filename
        }
        if progress > 0:
            detail_obj["progress"] = progress
        detail = json.dumps(detail_obj, ensure_ascii=False)
    else:
        message = f"åœæ­¢è½¬å†™å¤±è´¥: {filename}"
        if error:
            error_stack = ''.join(traceback.format_exception(type(error), error, error.__traceback__))
            detail = json.dumps({
                "file_id": file_id,
                "filename": filename,
                "error": error_stack
            }, ensure_ascii=False)
        else:
            detail = json.dumps({
                "file_id": file_id,
                "filename": filename,
                "error": "æœªçŸ¥é”™è¯¯"
            }, ensure_ascii=False)
    
    log_event(
        task_id=file_id,
        event_type="stop_transcribe",
        module="VoiceGateway",
        level=level,
        message=message,
        detail=detail,
        file_id=file_id,
        filename=filename
    )

