"""
Infra - ASRæ‰§è¡Œå™¨ï¼ˆFunASR AutoModelç‰ˆæœ¬ï¼‰
ä½¿ç”¨FunASRçš„AutoModelå®ç°ASRå’Œè¯´è¯äººè¯†åˆ«ä¸€ä½“åŒ–
ä¸demo.pyä¿æŒä¸€è‡´
"""

import os
import logging
import torch
from typing import Optional, List, Dict

# ç¦ç”¨FunASRçš„è¡¨å•æ‰“å°
os.environ['FUNASR_CACHE_DIR'] = os.path.expanduser('~/.cache/modelscope')
import warnings
warnings.filterwarnings('ignore')

from funasr import AutoModel

from .model_pool import ModelPool

logger = logging.getLogger(__name__)


class FunASRModelWrapper:
    """FunASR AutoModelåŒ…è£…å™¨ï¼Œç”¨äºæ± åŒ–ç®¡ç†"""
    
    def __init__(self, model_config: dict):
        logger.info("æ­£åœ¨åˆ›å»ºFunASR AutoModelå®ä¾‹...")
        
        # æ£€æµ‹è®¾å¤‡å’Œç¡¬ä»¶èµ„æºï¼ˆä¸demo.pyä¸€è‡´ï¼‰
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        ngpu = 1 if self.device == "cuda" else 0
        
        # è·å–CPUæ ¸å¿ƒæ•°ï¼ˆé™åˆ¶æœ€å¤§å€¼ï¼Œé¿å…è¶…å¤§æœåŠ¡å™¨å¯¼è‡´å†…å­˜é—®é¢˜ï¼‰
        try:
            import psutil
            ncpu = psutil.cpu_count()
        except:
            import multiprocessing
            ncpu = multiprocessing.cpu_count()
        
        # âš ï¸ é™åˆ¶CPUæ ¸å¿ƒæ•°ï¼Œé¿å…åœ¨å¤§å‹æœåŠ¡å™¨ä¸Šåˆ†é…è¿‡å¤šå†…å­˜
        # FunASRæ¯ä¸ªæ ¸å¿ƒä¼šåˆ†é…ä¸€å®šå†…å­˜ï¼Œ112æ ¸å¯èƒ½å¯¼è‡´OOM
        ncpu = min(ncpu, 16)  # æœ€å¤šä½¿ç”¨16ä¸ªæ ¸å¿ƒ
        
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}, GPUæ•°: {ngpu}, CPUæ ¸å¿ƒæ•°: {ncpu}")
        
        # åˆ›å»ºAutoModelï¼ˆé›†æˆASRã€VADã€PUNCã€è¯´è¯äººè¯†åˆ«ï¼‰
        # å‚æ•°ä¸demo.pyå®Œå…¨ä¸€è‡´
        self.model = AutoModel(
            model=model_config['asr']['model_id'],
            model_revision=model_config['asr']['model_revision'],
            vad_model=model_config['vad']['model_id'],
            vad_model_revision=model_config['vad']['model_revision'],
            punc_model=model_config['punc']['model_id'],
            punc_model_revision=model_config['punc']['model_revision'],
            spk_model=model_config['diarization']['model_id'],  # è¯´è¯äººè¯†åˆ«æ¨¡å‹
            spk_model_revision=model_config['diarization']['revision'],
            ngpu=ngpu,  # GPUæ•°é‡
            ncpu=ncpu,  # CPUæ ¸å¿ƒæ•°
            device=self.device,
            disable_pbar=True,
            disable_log=True,  # ç¦ç”¨æ—¥å¿—ï¼Œé˜²æ­¢æ‰“å°è¡¨å•
            disable_update=True
        )
        
        logger.info("FunASR AutoModelå®ä¾‹åˆ›å»ºæˆåŠŸ")
    
    def transcribe_with_speaker(self, audio_input, hotword: str = '') -> Dict:
        """
        æ‰§è¡ŒASRå’Œè¯´è¯äººè¯†åˆ«ï¼ˆä¸€ä½“åŒ–ï¼‰
        
        Args:
            audio_input: éŸ³é¢‘è¾“å…¥ï¼ˆå­—èŠ‚æµæˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            hotword: çƒ­è¯
            
        Returns:
            åŒ…å«æ–‡æœ¬å’Œè¯´è¯äººä¿¡æ¯çš„ç»“æœ
        """
        try:
            # å‡†å¤‡generateå‚æ•°
            generate_kwargs = {
                'input': audio_input,
                'use_itn': True,
                'batch_size_s': 60,
                'is_final': True,
                'sentence_timestamp': True
            }
            
            # åªæœ‰å½“hotwordéç©ºæ—¶æ‰ä¼ é€’ï¼ˆé¿å…ç©ºå­—ç¬¦ä¸²è¢«è§£æä¸º['<s>']ï¼‰
            if hotword and hotword.strip():
                generate_kwargs['hotword'] = hotword
            
            # è°ƒç”¨FunASRç”Ÿæˆ
            res = self.model.generate(**generate_kwargs)
            
            if not res or len(res) == 0:
                return None
            
            return res[0]  # è¿”å›ç¬¬ä¸€ä¸ªç»“æœ
            
        except Exception as e:
            logger.error(f"FunASRè½¬å†™å¤±è´¥: {e}")
            raise
    
    def cleanup(self):
        """æ¸…ç†æ¨¡å‹èµ„æº"""
        try:
            if hasattr(self, 'model'):
                del self.model
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except Exception as e:
            logger.error(f"æ¸…ç†FunASRæ¨¡å‹èµ„æºå¤±è´¥: {e}")


class ASRRunner:
    """ASRæ‰§è¡Œå™¨ - ä½¿ç”¨FunASR AutoModelï¼ˆæ”¯æŒæ¨¡å‹æ± ï¼‰"""
    
    def __init__(self, model_config: dict, use_pool: bool = True, pool_size: int = 3):
        """
        åˆå§‹åŒ–ASRè¿è¡Œå™¨ï¼ˆFunASRæ–¹å¼ï¼‰
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            use_pool: æ˜¯å¦ä½¿ç”¨æ¨¡å‹æ± ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èå¼€å¯ï¼‰
            pool_size: æ¨¡å‹æ± å¤§å°
        """
        self.model_config = model_config
        self.use_pool = use_pool
        
        # åŠ è½½æ—¶é—´æˆ³æ ¡æ­£é…ç½®
        try:
            from config import TIMESTAMP_CORRECTION_CONFIG
            self.ts_correction_enabled = TIMESTAMP_CORRECTION_CONFIG.get('enabled', False)
            self.ts_correction_factor = TIMESTAMP_CORRECTION_CONFIG.get('correction_factor', 1.0)
            if self.ts_correction_enabled and self.ts_correction_factor != 1.0:
                logger.info(f"ğŸ“ æ—¶é—´æˆ³æ ¡æ­£å·²å¯ç”¨ï¼Œæ ¡æ­£å› å­: {self.ts_correction_factor}")
        except ImportError:
            self.ts_correction_enabled = False
            self.ts_correction_factor = 1.0
        
        if use_pool:
            logger.info(f"ä½¿ç”¨FunASR AutoModel + æ¨¡å‹æ± æ¨¡å¼ï¼Œæ± å¤§å°: {pool_size}")
            # åˆ›å»ºæ¨¡å‹å·¥å‚å‡½æ•°
            def funasr_factory():
                return FunASRModelWrapper(model_config)
            
            # åˆ›å»ºæ¨¡å‹æ± 
            self.model_pool = ModelPool(
                model_factory=funasr_factory,
                initial_size=min(pool_size, 2),  # åˆå§‹åˆ›å»ºè¾ƒå°‘å®ä¾‹
                max_size=pool_size,
                min_size=1,
                max_idle_time=600,  # 10åˆ†é’Ÿ
                health_check_interval=300  # 5åˆ†é’Ÿï¼Œé™ä½æ—¥å¿—é¢‘ç‡
            )
            self.model = None
        else:
            logger.info("ä½¿ç”¨FunASR AutoModelå•ä¾‹æ¨¡å¼")
            self.model_pool = None
            self.model = FunASRModelWrapper(model_config)
    
    def transcribe_with_speaker(self, audio_input, hotword: str = '') -> Optional[List[Dict]]:
        """
        æ‰§è¡Œè¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«ï¼ˆFunASRä¸€ä½“åŒ–æ–¹å¼ï¼‰
        
        Args:
            audio_input: éŸ³é¢‘è¾“å…¥ï¼ˆå­—èŠ‚æµbytesæˆ–æ–‡ä»¶è·¯å¾„strï¼‰
            hotword: çƒ­è¯
            
        Returns:
            List[Dict]: è½¬å†™ç»“æœåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«ï¼š
                - text: æ–‡æœ¬å†…å®¹
                - start: å¼€å§‹æ—¶é—´(æ¯«ç§’)
                - end: ç»“æŸæ—¶é—´(æ¯«ç§’)
                - spk: è¯´è¯äººID
        """
        try:
            input_type = "å­—èŠ‚æµ" if isinstance(audio_input, bytes) else "æ–‡ä»¶"
            logger.info(f"ğŸ™ï¸ å¼€å§‹FunASRä¸€ä½“åŒ–è½¬å†™ (è¾“å…¥ç±»å‹: {input_type})")
            if hotword and hotword.strip():
                logger.info(f"ğŸ“ ä½¿ç”¨çƒ­è¯: {hotword}")
            else:
                logger.info("ğŸ“ æ— çƒ­è¯")
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹å¼
            if self.use_pool and self.model_pool:
                # ä½¿ç”¨æ¨¡å‹æ± 
                logger.info("â³ æ­£åœ¨ä»æ¨¡å‹æ± è·å–æ¨¡å‹å®ä¾‹...")
                with self.model_pool.acquire(timeout=60.0) as model:
                    logger.info("âœ… æ¨¡å‹è·å–æˆåŠŸï¼Œå¼€å§‹è½¬å½•...")
                    result = model.transcribe_with_speaker(audio_input, hotword)
            else:
                # ä½¿ç”¨å•ä¾‹æ¨¡å‹
                logger.info("ğŸ”„ ä½¿ç”¨å•ä¾‹æ¨¡å‹è¿›è¡Œè½¬å½•...")
                result = self.model.transcribe_with_speaker(audio_input, hotword)
            
            if not result:
                logger.warning("âš ï¸ FunASRè¿”å›ç©ºç»“æœ")
                return None
            
            # è§£æFunASRç»“æœæ ¼å¼
            transcript_list = []
            
            if 'sentence_info' in result:
                # æœ‰è¯´è¯äººä¿¡æ¯çš„ç»“æœ
                sentence_count = len(result['sentence_info'])
                
                # åˆ›å»ºè¯´è¯äººIDæ˜ å°„è¡¨ï¼ˆæŒ‰å‡ºç°é¡ºåºé‡æ–°ç¼–å·ï¼‰
                speaker_id_map = {}  # åŸå§‹spk -> è¿ç»­ç¼–å·
                next_speaker_number = 1
                
                # ç»Ÿè®¡æ—¶é—´æˆ³ä½¿ç”¨æƒ…å†µ
                ts_stats = {'native': 0, 'mapped': 0, 'interpolated': 0}
                
                for sentence in result['sentence_info']:
                    original_spk = sentence.get('spk', 0)
                    
                    # ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ä¸ªè¯´è¯äººæ—¶ï¼Œåˆ†é…æ–°çš„è¿ç»­ç¼–å·
                    if original_spk not in speaker_id_map:
                        speaker_id_map[original_spk] = next_speaker_number
                        next_speaker_number += 1
                    
                    # ä½¿ç”¨æ˜ å°„åçš„è¿ç»­ç¼–å·
                    speaker_number = speaker_id_map[original_spk]
                    
                    text = sentence.get('text', '')
                    start_time = sentence.get('start', 0) / 1000.0  # è½¬ä¸ºç§’
                    end_time = sentence.get('end', 0) / 1000.0
                    
                    # åº”ç”¨æ—¶é—´æˆ³æ ¡æ­£
                    if self.ts_correction_enabled:
                        start_time *= self.ts_correction_factor
                        end_time *= self.ts_correction_factor
                    
                    # æå–è¯çº§åˆ«æ—¶é—´æˆ³ï¼ˆæ ¡æ­£å› å­ä¼šåœ¨å†…éƒ¨æ–¹æ³•ä¸­åº”ç”¨ï¼‰
                    words, ts_method = self._extract_word_timestamps_with_stats(sentence, start_time, end_time, text)
                    ts_stats[ts_method] = ts_stats.get(ts_method, 0) + 1
                    
                    transcript_list.append({
                        'text': text,
                        'start_time': start_time,
                        'end_time': end_time,
                        'speaker': f"å‘è¨€äºº{speaker_number}",  # ä½¿ç”¨è¿ç»­ç¼–å·
                        'words': words  # è¯çº§åˆ«æ—¶é—´æˆ³
                    })
                
                # è¾“å‡ºæ—¶é—´æˆ³ç»Ÿè®¡
                logger.info(f"âœ… è¯†åˆ«å®Œæˆ: å…±{sentence_count}ä¸ªå¥å­, {len(speaker_id_map)}ä½è¯´è¯äºº")
                logger.info(f"ğŸ“Š æ—¶é—´æˆ³æ¥æº: åŸç”Ÿ={ts_stats.get('native', 0)}, æ˜ å°„={ts_stats.get('mapped', 0)}, æ’å€¼={ts_stats.get('interpolated', 0)}")
            elif 'text' in result:
                # åªæœ‰æ–‡æœ¬ï¼Œæ²¡æœ‰è¯´è¯äººä¿¡æ¯
                logger.warning("âš ï¸ ç»“æœä¸­æ— è¯´è¯äººä¿¡æ¯ï¼Œä½œä¸ºå•äººå¤„ç†")
                text = result['text']
                words = self._extract_word_timestamps(None, 0, 0, text)
                transcript_list.append({
                    'text': text,
                    'start_time': 0,
                    'end_time': 0,
                    'speaker': 'å‘è¨€äºº1',  # å•äººæ—¶é»˜è®¤ä¸ºå‘è¨€äºº1
                    'words': words
                })
            
            return transcript_list
            
        except Exception as e:
            logger.error(f"âŒ FunASRè½¬å†™å¤±è´¥: {e}")
            raise
    
    def _extract_word_timestamps_with_stats(self, sentence: Dict, start_time: float, end_time: float, text: str) -> tuple:
        """
        æå–è¯çº§åˆ«æ—¶é—´æˆ³ï¼Œå¹¶è¿”å›ä½¿ç”¨çš„æ–¹æ³•
        
        Returns:
            tuple: (è¯åˆ—è¡¨, æ–¹æ³•åç§°) - æ–¹æ³•åç§°ä¸º 'native', 'mapped', 'interpolated'
        """
        words, method = self._extract_word_timestamps_internal(sentence, start_time, end_time, text)
        return words, method
    
    def _extract_word_timestamps(self, sentence: Dict, start_time: float, end_time: float, text: str) -> List[Dict]:
        """æå–è¯çº§åˆ«æ—¶é—´æˆ³ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        words, _ = self._extract_word_timestamps_internal(sentence, start_time, end_time, text)
        return words
    
    def _extract_word_timestamps_internal(self, sentence: Dict, start_time: float, end_time: float, text: str) -> tuple:
        """
        æå–è¯çº§åˆ«æ—¶é—´æˆ³ï¼ˆæ™ºèƒ½ç‰ˆï¼šè¶…é•¿å¥å­æŒ‰å¥å·æ‹†åˆ†å­å¥ï¼Œæ¯ä¸ªå­å¥ç‹¬ç«‹è®¡ç®—æ—¶é—´æˆ³ï¼‰
        
        Returns:
            tuple: (è¯åˆ—è¡¨, æ–¹æ³•åç§°)
        """
        import jieba
        import re
        
        words = []
        
        # è·å–æ—¶é—´æˆ³æ ¡æ­£å› å­
        ts_factor = self.ts_correction_factor if self.ts_correction_enabled else 1.0
        
        # æ–¹æ³•1: å°è¯•ä»FunASRç»“æœä¸­æå– timestamp å­—æ®µï¼ˆå­—çº§åˆ«æ—¶é—´æˆ³ï¼‰
        if sentence and 'timestamp' in sentence:
            timestamp_list = sentence.get('timestamp', [])
            text_chars = list(text) if text else []
            
            if timestamp_list and len(timestamp_list) == len(text_chars):
                # æ—¶é—´æˆ³æ•°é‡ä¸å­—ç¬¦æ•°é‡åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨
                for i, (char, ts) in enumerate(zip(text_chars, timestamp_list)):
                    if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                        char_start = (ts[0] / 1000.0) * ts_factor
                        char_end = (ts[1] / 1000.0) * ts_factor
                        words.append({'text': char, 'start': char_start, 'end': char_end})
                
                if words:
                    return words, 'native'
                    
            elif timestamp_list:
                # FunASRçš„timestampä¸åŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œéœ€è¦æ˜ å°„
                PUNCTUATION_SET = set('ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€”â€¦Â·,.!?;:\'"()[]<>-â€“â€”')
                
                char_info = []
                ts_idx = 0
                for char in text_chars:
                    is_punct = char in PUNCTUATION_SET
                    if is_punct:
                        char_info.append((char, True, -1))
                    else:
                        char_info.append((char, False, ts_idx))
                        ts_idx += 1
                
                non_punct_count = sum(1 for c in char_info if not c[1])
                
                if non_punct_count == len(timestamp_list):
                    for i, (char, is_punct, ts_idx) in enumerate(char_info):
                        if is_punct:
                            if words:
                                punct_time = words[-1]['end']
                                words.append({'text': char, 'start': punct_time, 'end': punct_time})
                        else:
                            ts = timestamp_list[ts_idx]
                            if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                                words.append({'text': char, 'start': (ts[0] / 1000.0) * ts_factor, 'end': (ts[1] / 1000.0) * ts_factor})
                    
                    if words:
                        return words, 'native'
        
        # æ–¹æ³•1b: å°è¯•ä» words å­—æ®µæå–
        if sentence and 'words' in sentence:
            for word_info in sentence['words']:
                word_text = word_info.get('text', '')
                word_start = (word_info.get('start', 0) / 1000.0) * ts_factor
                word_end = (word_info.get('end', 0) / 1000.0) * ts_factor
                if word_text:
                    words.append({'text': word_text, 'start': word_start, 'end': word_end})
            if words:
                return words, 'native'
        
        # æ–¹æ³•2: åˆ†è¯+timestampæ˜ å°„
        if sentence and 'timestamp' in sentence:
            timestamp_list = sentence.get('timestamp', [])
            if timestamp_list and text:
                words = self._map_timestamps_to_words(text, timestamp_list, ts_factor)
                if words:
                    return words, 'mapped'
        
        # æ–¹æ³•3: æ™ºèƒ½åˆ†è¯+å­å¥æ’å€¼ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        if not text or not text.strip():
            return words, 'interpolated'
        
        try:
            # ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·é›†åˆ
            PUNCTUATION_SET = set('ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€”â€¦Â·,.!?;:\'"()[]<>-â€“â€”')
            # å¥å­ç»“æŸæ ‡ç‚¹ï¼ˆç”¨äºæ‹†åˆ†å­å¥ï¼‰
            SENTENCE_END_PUNCT = set('ã€‚ï¼ï¼Ÿ.!?')
            
            def is_punctuation(word: str) -> bool:
                """åˆ¤æ–­æ˜¯å¦ä¸ºçº¯æ ‡ç‚¹ç¬¦å·"""
                return all(c in PUNCTUATION_SET or c.isspace() for c in word)
            
            def is_sentence_end(word: str) -> bool:
                """åˆ¤æ–­æ˜¯å¦ä¸ºå¥å­ç»“æŸæ ‡ç‚¹"""
                return word in SENTENCE_END_PUNCT
            
            def estimate_syllables(word: str) -> int:
                """ä¼°ç®—è¯çš„éŸ³èŠ‚æ•°"""
                if is_punctuation(word):
                    return 0
                chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', word))
                english_part = re.sub(r'[\u4e00-\u9fff\d]', '', word)
                english_syllables = 0
                if english_part.strip():
                    vowel_groups = re.findall(r'[aeiouAEIOU]+', english_part)
                    english_syllables = max(1, len(vowel_groups)) if re.search(r'[a-zA-Z]', english_part) else 0
                digits = len(re.findall(r'\d', word))
                total = chinese_chars + english_syllables + digits
                return max(1, total) if total > 0 else 1
            
            def process_clause(word_list: list, clause_start: float, clause_end: float) -> list:
                """å¤„ç†å•ä¸ªå­å¥ï¼Œè¿”å›å¸¦æ—¶é—´æˆ³çš„è¯åˆ—è¡¨"""
                if not word_list:
                    return []
                
                clause_words = []
                duration = clause_end - clause_start
                if duration <= 0:
                    duration = max(len(word_list), 1) * 0.2
                    clause_end = clause_start + duration
                
                syllable_counts = [estimate_syllables(w) for w in word_list]
                total_syllables = sum(syllable_counts)
                
                if total_syllables == 0:
                    total_syllables = max(sum(1 for w in word_list if not is_punctuation(w)), 1)
                    syllable_counts = [1 if not is_punctuation(w) else 0 for w in word_list]
                
                current_time = clause_start
                for word, syllables in zip(word_list, syllable_counts):
                    if syllables == 0:
                        clause_words.append({'text': word, 'start': current_time, 'end': current_time})
                    else:
                        word_duration = (syllables / total_syllables) * duration
                        clause_words.append({'text': word, 'start': current_time, 'end': current_time + word_duration})
                        current_time += word_duration
                
                # ç¡®ä¿æœ€åä¸€ä¸ªéæ ‡ç‚¹è¯çš„ç»“æŸæ—¶é—´ç­‰äºå­å¥ç»“æŸæ—¶é—´
                for w in reversed(clause_words):
                    if w['start'] != w['end']:
                        w['end'] = clause_end
                        break
                
                return clause_words
            
            # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
            word_segments = list(jieba.cut(text, cut_all=False))
            word_list = [w for w in word_segments if w]
            
            if not word_list:
                return words, 'interpolated'
            
            duration = end_time - start_time
            if duration <= 0:
                non_punct_count = sum(1 for w in word_list if not is_punctuation(w))
                duration = max(non_punct_count, 1) * 0.3
                end_time = start_time + duration
            
            # ===== æ ¸å¿ƒæ”¹è¿›ï¼šæŒ‰å¥å·æ‹†åˆ†å­å¥ =====
            # åªæœ‰å½“å¥å­è¾ƒé•¿æ—¶æ‰æ‹†åˆ†ï¼ˆè¶…è¿‡20ç§’æˆ–è¶…è¿‡50ä¸ªè¯ï¼‰
            should_split = duration > 20 or len(word_list) > 50
            
            if should_split:
                # æ‹†åˆ†æˆå¤šä¸ªå­å¥
                clauses = []  # æ¯ä¸ªå…ƒç´ æ˜¯ (word_list, syllable_count)
                current_clause = []
                current_syllables = 0
                
                for word in word_list:
                    current_clause.append(word)
                    current_syllables += estimate_syllables(word)
                    
                    if is_sentence_end(word) and len(current_clause) > 1:
                        # é‡åˆ°å¥å·ï¼Œç»“æŸå½“å‰å­å¥
                        clauses.append((current_clause, current_syllables))
                        current_clause = []
                        current_syllables = 0
                
                # å¤„ç†æœ€åä¸€ä¸ªå­å¥ï¼ˆå¯èƒ½æ²¡æœ‰å¥å·ç»“å°¾ï¼‰
                if current_clause:
                    clauses.append((current_clause, current_syllables))
                
                # æŒ‰å­å¥éŸ³èŠ‚æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
                total_syllables = sum(c[1] for c in clauses)
                if total_syllables == 0:
                    total_syllables = len(clauses)
                
                current_time = start_time
                for clause_words, clause_syllables in clauses:
                    # è®¡ç®—å­å¥æ—¶é•¿
                    if clause_syllables == 0:
                        clause_syllables = max(sum(1 for w in clause_words if not is_punctuation(w)), 1)
                    clause_duration = (clause_syllables / total_syllables) * duration
                    clause_end = current_time + clause_duration
                    
                    # å¤„ç†å­å¥
                    clause_result = process_clause(clause_words, current_time, clause_end)
                    words.extend(clause_result)
                    
                    current_time = clause_end
                
                # ç¡®ä¿æœ€åä¸€ä¸ªè¯çš„ç»“æŸæ—¶é—´ç­‰äºå¥å­ç»“æŸæ—¶é—´
                if words:
                    for w in reversed(words):
                        if w['start'] != w['end']:
                            w['end'] = end_time
                            break
                
                logger.debug(f"è¶…é•¿å¥å­æ‹†åˆ†: {len(clauses)} ä¸ªå­å¥, {len(words)} ä¸ªè¯")
            else:
                # çŸ­å¥å­ç›´æ¥å¤„ç†
                words = process_clause(word_list, start_time, end_time)
                logger.debug(f"ä½¿ç”¨åˆ†è¯+éŸ³èŠ‚æ’å€¼: {len(words)} ä¸ªè¯")
            
            # éªŒè¯æ–‡æœ¬å®Œæ•´æ€§
            reconstructed_text = ''.join([w['text'] for w in words])
            if reconstructed_text.replace(' ', '') != text.replace(' ', ''):
                logger.warning(f"âš ï¸ åˆ†è¯åæ–‡æœ¬ä¸åŒ¹é…ï¼ŒåŸæ–‡æœ¬é•¿åº¦: {len(text)}, é‡å»ºé•¿åº¦: {len(reconstructed_text)}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ è¯çº§åˆ«æ—¶é—´æˆ³æå–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å¥å­çº§åˆ«æ—¶é—´æˆ³")
            if text.strip():
                words.append({
                    'text': text.strip(),
                    'start': start_time,
                    'end': end_time
                })
        
        return words, 'interpolated'
    
    def _map_timestamps_to_words(self, text: str, timestamp_list: List, ts_factor: float = 1.0) -> List[Dict]:
        """
        å°†FunASRçš„å­—çº§åˆ«timestampæ˜ å°„åˆ°è¯çº§åˆ«
        FunASRçš„timestampä¸åŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            timestamp_list: FunASRè¿”å›çš„timestampåˆ—è¡¨ [[start, end], ...]
            ts_factor: æ—¶é—´æˆ³æ ¡æ­£å› å­
            
        Returns:
            è¯çº§åˆ«æ—¶é—´æˆ³åˆ—è¡¨
        """
        import jieba
        
        words = []
        PUNCTUATION_SET = set('ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€”â€¦Â·,.!?;:\'"()[]<>-â€“â€”')
        
        try:
            # ä½¿ç”¨jiebaåˆ†è¯
            word_segments = list(jieba.cut(text, cut_all=False))
            word_list = [w for w in word_segments if w]
            
            # ä¸ºæ¯ä¸ªè¯è®¡ç®—æ—¶é—´æˆ³
            # timestampåªå¯¹åº”éæ ‡ç‚¹å­—ç¬¦ï¼Œæ‰€ä»¥éœ€è¦è·Ÿè¸ªts_index
            ts_index = 0
            
            for word in word_list:
                # æ£€æŸ¥è¿™ä¸ªè¯æ˜¯å¦æ˜¯çº¯æ ‡ç‚¹
                is_pure_punct = all(c in PUNCTUATION_SET for c in word)
                
                if is_pure_punct:
                    # æ ‡ç‚¹ä½¿ç”¨å‰ä¸€ä¸ªè¯çš„ç»“æŸæ—¶é—´
                    if words:
                        punct_time = words[-1]['end']
                        words.append({
                            'text': word,
                            'start': punct_time,
                            'end': punct_time
                        })
                else:
                    # è®¡ç®—è¿™ä¸ªè¯ä¸­çš„éæ ‡ç‚¹å­—ç¬¦æ•°
                    non_punct_chars = [c for c in word if c not in PUNCTUATION_SET]
                    num_non_punct = len(non_punct_chars)
                    
                    if ts_index + num_non_punct > len(timestamp_list):
                        # æ—¶é—´æˆ³ä¸å¤Ÿäº†ï¼Œè·³å‡º
                        break
                    
                    # è·å–è¯¥è¯çš„èµ·å§‹å’Œç»“æŸæ—¶é—´
                    word_start_ts = timestamp_list[ts_index]
                    word_end_ts = timestamp_list[ts_index + num_non_punct - 1]
                    
                    if isinstance(word_start_ts, (list, tuple)) and isinstance(word_end_ts, (list, tuple)):
                        word_start = (word_start_ts[0] / 1000.0) * ts_factor  # æ¯«ç§’è½¬ç§’ï¼Œå¹¶åº”ç”¨æ ¡æ­£
                        word_end = (word_end_ts[1] / 1000.0) * ts_factor
                        
                        words.append({
                            'text': word,
                            'start': word_start,
                            'end': word_end
                        })
                    
                    ts_index += num_non_punct
            
            return words
            
        except Exception as e:
            logger.warning(f"âš ï¸ timestampæ˜ å°„å¼‚å¸¸: {e}")
            return words
    
    def get_pool_stats(self) -> Optional[dict]:
        """è·å–æ¨¡å‹æ± ç»Ÿè®¡ä¿¡æ¯"""
        if self.use_pool and self.model_pool:
            return self.model_pool.get_stats()
        return None
    
    def shutdown(self):
        """å…³é—­è¿è¡Œå™¨ï¼Œæ¸…ç†èµ„æº"""
        if self.use_pool and self.model_pool:
            self.model_pool.shutdown()
        elif self.model:
            self.model.cleanup()

