# ðŸŽ™ï¸ Audio Transcription System - Project Guide for Claude

This document provides essential information for Claude instances to understand and work with this audio transcription system effectively.

## Project Overview

**Audio Transcription System** - An AI-powered real-time speech recognition and speaker diarization system built with Domain-Driven Design (DDD) architecture.

- **Technology Stack**: FastAPI + ModelScope + FunASR + Python 3.8+
- **Main Function**: Convert audio files to text with multi-speaker identification
- **Architecture**: DDDä¸‰å±‚æž¶æž„ (Domain-Application-Infra)
- **AI Models**: SeACo-Paraformer (ASR) + CAM++ (Speaker Diarization) + VAD + PUNC

## ðŸ—ï¸ Project Architecture

### Directory Structure

```
phosys/
â”œâ”€â”€ domain/                    # é¢†åŸŸå±‚ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ audio_processor.py    # éŸ³é¢‘å¤„ç†é€»è¾‘
â”‚       â”œâ”€â”€ text_processor.py     # æ–‡æœ¬å¤„ç†é€»è¾‘  
â”‚       â”œâ”€â”€ diarization.py       # å£°çº¹åˆ†ç¦»ä¸šåŠ¡è§„åˆ™
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ application/              # åº”ç”¨å±‚ - ä¸šåŠ¡æµç¨‹ç¼–æŽ’
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ pipeline_service_funasr.py  # è½¬å†™æµæ°´çº¿æœåŠ¡
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ infra/                    # åŸºç¡€è®¾æ–½å±‚ - æŠ€æœ¯å®žçŽ°
â”‚   â”œâ”€â”€ audio_io/             # éŸ³é¢‘å­˜å‚¨ç®¡ç†
â”‚   â”‚   â””â”€â”€ storage.py
â”‚   â”œâ”€â”€ runners/              # æ¨¡åž‹è¿è¡Œå™¨
â”‚   â”‚   â”œâ”€â”€ asr_runner_funasr.py      # ASRæ‰§è¡Œå™¨(FunASR)
â”‚   â”‚   â””â”€â”€ model_pool.py              # æ¨¡åž‹æ± ç®¡ç†
â”‚   â”œâ”€â”€ websocket/            # WebSocketç®¡ç†
â”‚   â”‚   â””â”€â”€ connection_manager.py
â”‚   â”œâ”€â”€ monitoring/           # ç›‘æŽ§æŒ‡æ ‡
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ middleware/           # ä¸­é—´ä»¶
â”‚   â”‚   â””â”€â”€ rate_limiter.py
â”‚   â””â”€â”€ cache/                # ç¼“å­˜
â”‚
â”œâ”€â”€ api/                      # APIå±‚ - å¯¹å¤–æŽ¥å£
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ voice_gateway.py  # è¯­éŸ³æœåŠ¡ç½‘å…³
â”‚
â”œâ”€â”€ templates/                # å‰ç«¯æ¨¡æ¿
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ result.html
â”œâ”€â”€ static/                   # é™æ€èµ„æº
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”œâ”€â”€ uploads/                  # ä¸Šä¼ æ–‡ä»¶ç›®å½•
â”œâ”€â”€ transcripts/              # è½¬å†™ç»“æžœç›®å½•
â”œâ”€â”€ audio_temp/               # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
â”œâ”€â”€ main.py                   # åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…
â”œâ”€â”€ README.md                 # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ app.log                   # åº”ç”¨æ—¥å¿—
â””â”€â”€ CLAUDE.md                 # æœ¬æ–‡ä»¶
```

### Key Architectural Components

#### 1. Domain Layer (ä¸šåŠ¡é¢†åŸŸå±‚)
- **Purpose**: Core business logic, independent of external frameworks
- **Key Files**:
  - `domain/voice/audio_processor.py` - Audio format conversion and preprocessing
  - `domain/voice/diarization.py` - Speaker diarization business rules and post-processing
  - `domain/voice/text_processor.py` - Text processing and formatting

#### 2. Application Layer (åº”ç”¨å±‚)  
- **Purpose**: Business process orchestration, coordinates domain objects
- **Key Files**:
  - `application/voice/pipeline_service_funasr.py` - Main transcription pipeline using FunASR

#### 3. Infrastructure Layer (åŸºç¡€è®¾æ–½å±‚)
- **Purpose**: Technical implementation support
- **Key Files**:
  - `infra/audio_io/storage.py` - File storage and management
  - `infra/runners/asr_runner_funasr.py` - ASR model execution with FunASR
  - `infra/runners/model_pool.py` - Model pooling for concurrent processing
  - `infra/websocket/connection_manager.py` - WebSocket real-time communication

#### 4. API Layer (æŽ¥å£å±‚)
- **Purpose**: HTTP request handling and response generation
- **Key Files**:
  - `api/routers/voice_gateway.py` - Complete API gateway with multiple endpoints

## ðŸ”§ Configuration

### Main Configuration (config.py)

```python
# File paths
FILE_CONFIG = {
    "output_dir": "transcripts",     # è½¬å†™ç»“æžœç›®å½•
    "temp_dir": "audio_temp",       # ä¸´æ—¶æ–‡ä»¶ç›®å½•  
    "upload_dir": "uploads"         # ä¸Šä¼ æ–‡ä»¶ç›®å½•
}

# AI Models
MODEL_CONFIG = {
    "diarization": {
        "model_id": 'iic/speech_campplus_sv_zh-cn_16k-common',
        "revision": 'v2.0.2'
    },
    "asr": {
        "model_id": 'iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',
        "model_revision": 'v2.0.4'
    },
    "vad": {
        "model_id": 'iic/speech_fsmn_vad_zh-cn-16k-common-pytorch',
        "model_revision": 'v2.0.4'
    },
    "punc": {
        "model_id": 'iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch', 
        "model_revision": 'v2.0.4'
    }
}

# Concurrency settings
CONCURRENCY_CONFIG = {
    "use_model_pool": True,
    "asr_pool_size": 6,              # ASRæ¨¡åž‹æ± å¤§å°
    "transcription_workers": 12,     # è½¬å†™ä»»åŠ¡å¹¶å‘æ•°
    "max_memory_mb": 8192,          # å†…å­˜é™åˆ¶
}
```

### Environment Variables

```bash
# AI API Keys (optional for meeting summaries)
# æ”¯æŒ DeepSeekã€Qwenã€GLM ä¸‰ç§æ¨¡åž‹ï¼Œåœ¨ config.py ä¸­é…ç½®
export DEEPSEEK_API_KEY="your-api-key"
export DEEPSEEK_API_BASE="https://api.deepseek.com"
export DEEPSEEK_MODEL="deepseek-chat"

# Qwen æ¨¡åž‹é…ç½®ï¼ˆå¯é€‰ï¼‰
export QWEN_API_KEY="your-api-key"
export QWEN_API_BASE="https://dashscope.aliyuncs.com/compatible-mode/v1"

# GLM æ¨¡åž‹é…ç½®ï¼ˆå¯é€‰ï¼‰
export GLM_API_KEY="your-api-key"
export GLM_API_BASE="https://open.bigmodel.cn/api/paas/v4"

# Optional settings
export PRELOAD_MODELS="true"           # é¢„åŠ è½½æ¨¡åž‹
export TRANSCRIBE_WORKERS="12"         # è½¬å†™çº¿ç¨‹æ•°
```

## ðŸš€ Running the System

### Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Check FFmpeg installation
which ffmpeg

# 3. Start the service
python main.py

# Service will be available at:
# Main page: http://localhost:8998
# API docs: http://localhost:8998/docs
# Health check: http://localhost:8998/healthz
```

### Development Mode

```bash
# With auto-reload
uvicorn main:app --host 0.0.0.0 --port 8998 --reload

# Background mode
nohup python main.py > app.log 2>&1 &
```

## ðŸ“¡ API Usage Guide

### Primary Interface: Transcription API

```bash
# 1. Upload audio file
FILE_ID=$(curl -X POST "http://localhost:8998/api/voice/upload" \
  -F "audio_file=@meeting.mp3" | jq -r '.file.id')

# 2. Start transcription (wait for completion)
curl -X POST "http://localhost:8998/api/voice/transcribe" \
  -H "Content-Type: application/json" \
  -d "{\"file_id\": \"$FILE_ID\", \"language\": \"zh\", \"wait\": true}"

# 3. Get result
curl "http://localhost:8998/api/voice/result/$FILE_ID"
```

### RESTful File Management

```bash
# List all files (returns files with download_urls field)
curl "http://localhost:8998/api/voice/files"

# List completed files
curl "http://localhost:8998/api/voice/files?status=completed"

# List files with history
curl "http://localhost:8998/api/voice/files?include_history=true"

# Pagination (page 2, 20 items per page)
curl "http://localhost:8998/api/voice/files?limit=20&offset=20"

# Get file details with transcript
curl "http://localhost:8998/api/voice/files/{file_id}?include_transcript=true"

# Retranscribe file
curl -X PATCH "http://localhost:8998/api/voice/files/{file_id}" \
  -H "Content-Type: application/json" \
  -d '{"action": "retranscribe", "language": "zh"}'

# Delete file
curl -X DELETE "http://localhost:8998/api/voice/files/{file_id}"
```

**Note**: The `/api/voice/files` endpoint returns files with `download_urls` field. Use `download_urls.audio` to access audio files, not the `filepath` field (which is a server local path).

## ðŸ”‘ Key Classes and Their Responsibilities

### Domain Classes

- **`DiarizationProcessor`** (`domain/voice/diarization.py`): Handles speaker diarization business logic, post-processing of segments, merging nearby segments
- **`AudioProcessor`** (`domain/voice/audio_processor.py`): Audio format conversion and preprocessing with GPU acceleration
- **`TextProcessor`** (`domain/voice/text_processor.py`): Text processing and formatting logic

### Application Classes

- **`PipelineService`** (`application/voice/pipeline_service_funasr.py`): Main orchestration service that coordinates the entire transcription workflow using FunASR

### Infrastructure Classes

- **`AudioStorage`** (`infra/audio_io/storage.py`): Manages file upload, temporary storage, and cleanup
- **`ASRRunner`** (`infra/runners/asr_runner_funasr.py`): ASR model execution with FunASR AutoModel and model pooling
- **`ModelPool`** (`infra/runners/model_pool.py`): Advanced object pooling for concurrent model instances
- **`ConnectionManager`** (`infra/websocket/connection_manager.py`): WebSocket real-time communication

### API Classes

- **`voice_gateway`** (`api/routers/voice_gateway.py`): Complete API router with multiple endpoints and file management

## ðŸ§ª Development Tasks

### Common Development Activities

1. **Adding New Audio Formats**: Update `domain/voice/audio_processor.py` and the `allowed_file()` function in `voice_gateway.py`

2. **Extending AI Models**: Update `MODEL_CONFIG` in `config.py` and modify the corresponding runner in `infra/runners/`

3. **Adding New API Endpoints**: Add new routes to `api/routers/voice_gateway.py` following the existing patterns

4. **Modifying Business Logic**: Changes to core business rules should go in the `domain/` layer

5. **Performance Tuning**: Adjust `CONCURRENCY_CONFIG` in `config.py` and modify model pool settings in `infra/runners/model_pool.py`

### Testing and Debugging

```bash
# Check system status
curl "http://localhost:8998/api/status"

# View application logs
tail -f app.log

# Monitor model pool stats
curl "http://localhost:8998/api/metrics"
```

### Adding Dependencies

```bash
# Add to requirements.txt
echo "new-package==1.0.0" >> requirements.txt
pip install new-package==1.0.0
```

## ðŸš¨ Important Notes for Claude Instances

### Architecture Principles

1. **DDD Strictly**: Always follow the DDD layers - Domain should not depend on Application or Infrastructure
2. **FunASR Integration**: The system uses FunASR AutoModel for integrated ASR + speaker diarization
3. **Model Pooling**: Production uses model pooling for concurrency - avoid global locks
4. **WebSocket Support**: Real-time progress updates via WebSocket (`/api/voice/ws`)

### Code Patterns to Follow

- **Error Handling**: Use try-catch blocks with detailed logging
- **File Management**: Use `AudioStorage` class for all file operations
- **Concurrency**: Use the thread pool pattern with `TRANSCRIPTION_THREAD_POOL`
- **Progress Callbacks**: Use the progress callback pattern for real-time updates
- **Configuration**: Use `config.py` for all configuration, avoid hard-coded values

### Common Pitfalls to Avoid

1. **Global State**: Use the `ThreadSafeFileManager` instead of global variables
2. **Model Loading**: Let the model pool handle model loading - don't load models directly
3. **Memory Management**: Monitor memory usage in `CONCURRENCY_CONFIG`
4. **File Paths**: Use absolute paths consistently
5. **Async/Sync Mixing**: Be careful when mixing async and sync code - use `asyncio.run_coroutine_threadsafe` for WebSocket from sync threads

### Performance Considerations

- The system is optimized for batch processing with high concurrency
- Model pooling reduces initialization overhead for repeated tasks  
- GPU acceleration is enabled for audio processing when available
- Memory limits prevent system overload on large servers

## ðŸ”„ Version Information

- **Current Version**: 3.1.3-FunASR
- **Architecture**: DDD with FunASR integration
- **Last Updated**: 2025-12-04
- **Python Version**: 3.8+
- **Framework**: FastAPI 0.120.4

### Recent Updates (v3.1.3-FunASR, 2025-12-04)

#### API Simplification
- âœ… **Removed One-Stop Transcription Interface**: Deleted `/api/voice/transcribe_all` endpoint
- âœ… **Removed Clear Dify Files Feature**: Deleted `_clear_dify` special operation
- âœ… **Enhanced Transcription API**: Improved `POST /api/voice/transcribe` with `wait=true` to return transcript directly without words field

### Previous Updates (v3.1.1-FunASR, 2025-11-13)

#### New Features
- âœ… **True Stop Transcription**: Implemented real task interruption using `_cancelled` flag and `InterruptedError` mechanism
- âœ… **Clear All History**: New endpoint `DELETE /api/voice/files/_clear_all` to clear all transcription history

#### Bug Fixes
- âœ… **Filename Uniqueness**: Fixed filename conflicts in batch transcription by using microsecond timestamps and `file_id`
- âœ… **Delete Stopped Files**: Fixed issue where stopped transcription files couldn't be deleted
- âœ… **WebSocket Progress Jump**: Fixed progress jumping issue, ensuring progress only increases
- âœ… **UI Update After Delete**: Fixed issue where UI didn't update immediately after file deletion
- âœ… **Delete Error Message**: Fixed incorrect "deletion failed" message when deleting stopped transcription files

#### Technical Improvements
- âœ… Improved cancellation mechanism using `cancellation_flag` to check cancellation status at key steps
- âœ… Optimized WebSocket message handling to prevent progress regression
- âœ… Improved error handling for file deletion, correctly parsing FastAPI HTTPException responses

## ðŸ“š Related Documentation

- [API Documentation](http://localhost:8998/docs) - Auto-generated FastAPI docs
- [README.md](README.md) - Complete project documentation and usage guide
- [ModelScope Models](https://modelscope.cn/) - AI model platform documentation
- [FunASR](https://github.com/alibaba-damo-academy/FunASR) - Speech recognition framework

---

This guide should provide Claude instances with the essential context needed to understand and work effectively with this audio transcription system. Always refer to the actual code files for the most current implementation details.
