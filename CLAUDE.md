# ðŸŽ™ï¸ Audio Transcription System - Project Guide for Claude

This document provides essential information for Claude instances to understand and work with this audio transcription system effectively.

## Project Overview

**Audio Transcription System** - An AI-powered real-time speech recognition and speaker diarization system built with Domain-Driven Design (DDD) architecture.

- **Technology Stack**: FastAPI + ModelScope + FunASR + Python 3.8+
- **Main Function**: Convert audio files to text with multi-speaker identification
- **Architecture**: DDDä¸‰å±‚æž¶æž„ (Domain-Application-Infra)
- **AI Models**: SeACo-Paraformer (ASR) + CAM++ (Speaker Diarization) + VAD + PUNC

## ðŸ—ï¸ Project Architecture

### Directory Structure

```
phosys/
â”œâ”€â”€ domain/                    # é¢†åŸŸå±‚ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ audio_processor.py    # éŸ³é¢‘å¤„ç†é€»è¾‘
â”‚       â”œâ”€â”€ text_processor.py     # æ–‡æœ¬å¤„ç†é€»è¾‘  
â”‚       â”œâ”€â”€ diarization.py       # å£°çº¹åˆ†ç¦»ä¸šåŠ¡è§„åˆ™
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ application/              # åº”ç”¨å±‚ - ä¸šåŠ¡æµç¨‹ç¼–æŽ’
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ pipeline_service_funasr.py  # è½¬å†™æµæ°´çº¿æœåŠ¡
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ infra/                    # åŸºç¡€è®¾æ–½å±‚ - æŠ€æœ¯å®žçŽ°
â”‚   â”œâ”€â”€ audio_io/             # éŸ³é¢‘å­˜å‚¨ç®¡ç†
â”‚   â”‚   â””â”€â”€ storage.py
â”‚   â”œâ”€â”€ runners/              # æ¨¡åž‹è¿è¡Œå™¨
â”‚   â”‚   â”œâ”€â”€ asr_runner_funasr.py      # ASRæ‰§è¡Œå™¨(FunASR)
â”‚   â”‚   â””â”€â”€ model_pool.py              # æ¨¡åž‹æ± ç®¡ç†
â”‚   â”œâ”€â”€ websocket/            # WebSocketç®¡ç†
â”‚   â”‚   â””â”€â”€ connection_manager.py
â”‚   â”œâ”€â”€ monitoring/           # ç›‘æŽ§å’ŒæŒ‡æ ‡
â”‚   â”‚   â”œâ”€â”€ dify_webhook_sender.py    # Dify Webhook æŠ¥è­¦
â”‚   â”‚   â”œâ”€â”€ metrics.py                # ç³»ç»ŸæŒ‡æ ‡
â”‚   â”‚   â””â”€â”€ prometheus_metrics.py     # Prometheus æŒ‡æ ‡
â”‚   â”œâ”€â”€ middleware/           # ä¸­é—´ä»¶
â”‚   â”‚   â””â”€â”€ rate_limiter.py
â”‚   â”œâ”€â”€ cache/                # ç¼“å­˜
â”‚   â””â”€â”€ repos/                # æ•°æ®ä»“åº“ï¼ˆé¢„ç•™ï¼‰
â”‚
â”œâ”€â”€ api/                      # APIå±‚ - å¯¹å¤–æŽ¥å£
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ voice_gateway.py        # è¯­éŸ³æœåŠ¡ç½‘å…³ï¼ˆä¸»è·¯ç”±å®šä¹‰ï¼‰
â”‚       â”œâ”€â”€ file_handlers.py        # æ–‡ä»¶å¤„ç†ï¼ˆä¸Šä¼ ã€ä¸‹è½½ã€åˆ é™¤ï¼‰
â”‚       â”œâ”€â”€ file_manager.py         # çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶ç®¡ç†å™¨
â”‚       â”œâ”€â”€ history_manager.py      # åŽ†å²è®°å½•ç®¡ç†ï¼ˆåŠ è½½ã€ä¿å­˜ï¼‰
â”‚       â”œâ”€â”€ transcription_service.py # è½¬å†™æœåŠ¡ï¼ˆè½¬å†™ä»»åŠ¡ç®¡ç†ï¼‰
â”‚       â”œâ”€â”€ summary_generator.py    # ä¼šè®®çºªè¦ç”ŸæˆæœåŠ¡
â”‚       â”œâ”€â”€ document_generator.py   # Word æ–‡æ¡£ç”Ÿæˆï¼ˆè½¬å†™æ–‡æ¡£ã€ä¼šè®®çºªè¦ï¼‰
â”‚       â””â”€â”€ utils.py                # å·¥å…·å‡½æ•°ï¼ˆWebSocketã€æ–‡ä»¶éªŒè¯ç­‰ï¼‰
â”‚
â”œâ”€â”€ templates/                # å‰ç«¯æ¨¡æ¿
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ result.html
â”œâ”€â”€ static/                   # é™æ€èµ„æº
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”œâ”€â”€ uploads/                  # ä¸Šä¼ æ–‡ä»¶ç›®å½•
â”œâ”€â”€ transcripts/              # è½¬å†™ç»“æžœç›®å½•
â”œâ”€â”€ audio_temp/               # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
â”œâ”€â”€ meeting_summaries/         # ä¼šè®®çºªè¦å­˜å‚¨ç›®å½•
â”œâ”€â”€ main.py                   # åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…
â”œâ”€â”€ README.md                 # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ app.log                   # åº”ç”¨æ—¥å¿—
â””â”€â”€ CLAUDE.md                 # æœ¬æ–‡ä»¶
```

### Key Architectural Components

#### 1. Domain Layer (ä¸šåŠ¡é¢†åŸŸå±‚)
- **Purpose**: Core business logic, independent of external frameworks
- **Key Files**:
  - `domain/voice/audio_processor.py` - Audio format conversion and preprocessing
  - `domain/voice/diarization.py` - Speaker diarization business rules and post-processing
  - `domain/voice/text_processor.py` - Text processing and formatting

#### 2. Application Layer (åº”ç”¨å±‚)  
- **Purpose**: Business process orchestration, coordinates domain objects
- **Key Files**:
  - `application/voice/pipeline_service_funasr.py` - Main transcription pipeline using FunASR

#### 3. Infrastructure Layer (åŸºç¡€è®¾æ–½å±‚)
- **Purpose**: Technical implementation support
- **Key Files**:
  - `infra/audio_io/storage.py` - File storage and management
  - `infra/runners/asr_runner_funasr.py` - ASR model execution with FunASR
  - `infra/runners/model_pool.py` - Model pooling for concurrent processing
  - `infra/websocket/connection_manager.py` - WebSocket real-time communication
  - `infra/monitoring/dify_webhook_sender.py` - Dify Webhook event notifications
  - `infra/monitoring/prometheus_metrics.py` - Prometheus metrics collection
  - `infra/middleware/rate_limiter.py` - API rate limiting

#### 4. API Layer (æŽ¥å£å±‚)
- **Purpose**: HTTP request handling and response generation
- **Key Files**:
  - `api/routers/voice_gateway.py` - Main API router with route definitions
  - `api/routers/file_handlers.py` - File upload, download, and deletion handlers
  - `api/routers/file_manager.py` - Thread-safe file information management
  - `api/routers/transcription_service.py` - Transcription task management and execution
  - `api/routers/history_manager.py` - History record loading and saving
  - `api/routers/summary_generator.py` - Meeting summary generation using AI models
  - `api/routers/document_generator.py` - Word document generation for transcripts and summaries
  - `api/routers/utils.py` - Utility functions (WebSocket, file validation, etc.)

## ðŸ”§ Configuration

### Main Configuration (config.py)

```python
# File paths
FILE_CONFIG = {
    "output_dir": "transcripts",     # è½¬å†™ç»“æžœç›®å½•
    "temp_dir": "audio_temp",       # ä¸´æ—¶æ–‡ä»¶ç›®å½•  
    "upload_dir": "uploads"         # ä¸Šä¼ æ–‡ä»¶ç›®å½•
}

# AI Models
MODEL_CONFIG = {
    "diarization": {
        "model_id": 'iic/speech_campplus_sv_zh-cn_16k-common',
        "revision": 'v2.0.2'
    },
    "asr": {
        "model_id": 'iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',
        "model_revision": 'v2.0.4'
    },
    "vad": {
        "model_id": 'iic/speech_fsmn_vad_zh-cn-16k-common-pytorch',
        "model_revision": 'v2.0.4'
    },
    "punc": {
        "model_id": 'iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch', 
        "model_revision": 'v2.0.4'
    }
}

# Concurrency settings
CONCURRENCY_CONFIG = {
    "use_model_pool": True,
    "asr_pool_size": 6,              # ASRæ¨¡åž‹æ± å¤§å°
    "transcription_workers": 12,     # è½¬å†™ä»»åŠ¡å¹¶å‘æ•°
    "max_memory_mb": 8192,          # å†…å­˜é™åˆ¶
}

# Audio preprocessing (optional)
AUDIO_PREPROCESS_CONFIG = {
    "enabled": True,              # Enable preprocessing on upload
    "replace_original": True,      # Replace original file
    "target_sample_rate": 16000,  # Target sample rate
    "target_channels": 1,         # Target channels
    "output_format": "wav",      # Output format
    "output_codec": "pcm_s16le", # Output codec
    "use_gpu_accel": False,      # Use GPU acceleration
    "fallback_on_error": True    # Keep original on error
}
```

### Environment Variables

```bash
# AI API Keys (optional for meeting summaries)
# æ”¯æŒ DeepSeekã€Qwenã€GLM ä¸‰ç§æ¨¡åž‹ï¼Œåœ¨ config.py ä¸­é…ç½®
export DEEPSEEK_API_KEY="your-api-key"
export DEEPSEEK_API_BASE="https://api.deepseek.com"
export DEEPSEEK_MODEL="deepseek-chat"

# Qwen æ¨¡åž‹é…ç½®ï¼ˆå¯é€‰ï¼‰
export QWEN_API_KEY="your-api-key"
export QWEN_API_BASE="https://dashscope.aliyuncs.com/compatible-mode/v1"

# GLM æ¨¡åž‹é…ç½®ï¼ˆå¯é€‰ï¼‰
export GLM_API_KEY="your-api-key"
export GLM_API_BASE="https://open.bigmodel.cn/api/paas/v4"

# Optional settings
export PRELOAD_MODELS="true"           # é¢„åŠ è½½æ¨¡åž‹
export TRANSCRIBE_WORKERS="12"         # è½¬å†™çº¿ç¨‹æ•°
export AUDIO_PREPROCESS_ENABLED="true" # å¯ç”¨ä¸Šä¼ æ—¶éŸ³é¢‘é¢„å¤„ç†
export AUDIO_PREPROCESS_GPU="false"    # ä½¿ç”¨GPUåŠ é€Ÿé¢„å¤„ç†

# Dify Webhook (optional)
export DIFY_API_KEY="your-api-key"
export DIFY_BASE_URL="http://your-dify:5001"
export DIFY_WORKFLOW_ID="optional-workflow-id"
export DIFY_USER_ID="your-user-id"
```

## ðŸš€ Running the System

### Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Check FFmpeg installation
which ffmpeg

# 3. Start the service
python main.py

# Service will be available at:
# Main page: http://localhost:8998
# API docs: http://localhost:8998/docs
# Health check: http://localhost:8998/healthz
```

### Development Mode

```bash
# With auto-reload
uvicorn main:app --host 0.0.0.0 --port 8998 --reload

# Background mode
nohup python main.py > app.log 2>&1 &
```

## ðŸ“¡ API Usage Guide

### Primary Interface: Transcription API

```bash
# 1. Upload audio file
FILE_ID=$(curl -X POST "http://localhost:8998/api/voice/upload" \
  -F "audio_file=@meeting.mp3" | jq -r '.file.id')

# 2. Start transcription (wait for completion)
curl -X POST "http://localhost:8998/api/voice/transcribe" \
  -H "Content-Type: application/json" \
  -d "{\"file_id\": \"$FILE_ID\", \"language\": \"zh\", \"wait\": true}"

# 3. Get result
curl "http://localhost:8998/api/voice/result/$FILE_ID"
```

### RESTful File Management

```bash
# List all files (returns files with download_urls field)
curl "http://localhost:8998/api/voice/files"

# List completed files
curl "http://localhost:8998/api/voice/files?status=completed"

# List files with history
curl "http://localhost:8998/api/voice/files?include_history=true"

# Pagination (page 2, 20 items per page)
curl "http://localhost:8998/api/voice/files?limit=20&offset=20"

# Get file details with transcript
curl "http://localhost:8998/api/voice/files/{file_id}?include_transcript=true"

# Retranscribe file
curl -X PATCH "http://localhost:8998/api/voice/files/{file_id}" \
  -H "Content-Type: application/json" \
  -d '{"action": "retranscribe", "language": "zh"}'

# Delete file
curl -X DELETE "http://localhost:8998/api/voice/files/{file_id}"
```

**Note**: The `/api/voice/files` endpoint returns files with `download_urls` field. Use `download_urls.audio` to access audio files, not the `filepath` field (which is a server local path).

## ðŸ”‘ Key Classes and Their Responsibilities

### Domain Classes

- **`DiarizationProcessor`** (`domain/voice/diarization.py`): Handles speaker diarization business logic, post-processing of segments, merging nearby segments
- **`AudioProcessor`** (`domain/voice/audio_processor.py`): Audio format conversion and preprocessing with GPU acceleration
- **`TextProcessor`** (`domain/voice/text_processor.py`): Text processing and formatting logic

### Application Classes

- **`PipelineService`** (`application/voice/pipeline_service_funasr.py`): Main orchestration service that coordinates the entire transcription workflow using FunASR

### Infrastructure Classes

- **`AudioStorage`** (`infra/audio_io/storage.py`): Manages file upload, temporary storage, and cleanup
- **`ASRRunner`** (`infra/runners/asr_runner_funasr.py`): ASR model execution with FunASR AutoModel and model pooling
- **`ModelPool`** (`infra/runners/model_pool.py`): Advanced object pooling for concurrent model instances
- **`ConnectionManager`** (`infra/websocket/connection_manager.py`): WebSocket real-time communication

### API Classes

- **`voice_gateway`** (`api/routers/voice_gateway.py`): Main API router with route definitions
- **`FileHandlers`** (`api/routers/file_handlers.py`): Handles file upload, download, and deletion operations
- **`ThreadSafeFileManager`** (`api/routers/file_manager.py`): Thread-safe file information management
- **`TranscriptionService`** (`api/routers/transcription_service.py`): Manages transcription tasks and execution
- **`history_manager`** (`api/routers/history_manager.py`): Loads and saves transcription history
- **`summary_generator`** (`api/routers/summary_generator.py`): Generates meeting summaries using AI models
- **`document_generator`** (`api/routers/document_generator.py`): Generates Word documents for transcripts and summaries
- **`utils`** (`api/routers/utils.py`): Utility functions for WebSocket, file validation, etc.

## ðŸ§ª Development Tasks

### Common Development Activities

1. **Adding New Audio Formats**: Update `domain/voice/audio_processor.py` and the `allowed_file()` function in `voice_gateway.py`

2. **Extending AI Models**: Update `MODEL_CONFIG` in `config.py` and modify the corresponding runner in `infra/runners/`

3. **Adding New API Endpoints**: Add new routes to `api/routers/voice_gateway.py` following the existing patterns

4. **Modifying Business Logic**: Changes to core business rules should go in the `domain/` layer

5. **Performance Tuning**: Adjust `CONCURRENCY_CONFIG` in `config.py` and modify model pool settings in `infra/runners/model_pool.py`

### Testing and Debugging

```bash
# Check system status
curl "http://localhost:8998/api/status"

# View application logs
tail -f app.log

# Monitor model pool stats
curl "http://localhost:8998/api/metrics"
```

### Adding Dependencies

```bash
# Add to requirements.txt
echo "new-package==1.0.0" >> requirements.txt
pip install new-package==1.0.0
```

## ðŸš¨ Important Notes for Claude Instances

### Architecture Principles

1. **DDD Strictly**: Always follow the DDD layers - Domain should not depend on Application or Infrastructure
2. **FunASR Integration**: The system uses FunASR AutoModel for integrated ASR + speaker diarization
3. **Model Pooling**: Production uses model pooling for concurrency - avoid global locks
4. **WebSocket Support**: Real-time progress updates via WebSocket (`/api/voice/ws`)

### Code Patterns to Follow

- **Error Handling**: Use try-catch blocks with detailed logging
- **File Management**: Use `AudioStorage` class for all file operations
- **Concurrency**: Use the thread pool pattern with `TRANSCRIPTION_THREAD_POOL`
- **Progress Callbacks**: Use the progress callback pattern for real-time updates
- **Configuration**: Use `config.py` for all configuration, avoid hard-coded values
- **Module Separation**: Keep business logic in separate modules (file_handlers, transcription_service, etc.)
- **Thread Safety**: Use `ThreadSafeFileManager` for file information management
- **WebSocket**: Use `send_ws_message_sync` from utils for sending messages from sync code

### Common Pitfalls to Avoid

1. **Global State**: Use the `ThreadSafeFileManager` instead of global variables
2. **Model Loading**: Let the model pool handle model loading - don't load models directly
3. **Memory Management**: Monitor memory usage in `CONCURRENCY_CONFIG`
4. **File Paths**: Use absolute paths consistently
5. **Async/Sync Mixing**: Be careful when mixing async and sync code - use `asyncio.run_coroutine_threadsafe` for WebSocket from sync threads
6. **Health Check Fields**: Use correct field names (`available_count`, `current_size`) when checking model pool stats
7. **Docker Environment Variables**: Ensure `.env` file is in project root and run Docker Compose from root directory
8. **Lazy Loading**: Model not loaded is normal state - don't mark service as unhealthy
9. **Module Dependencies**: Don't create circular imports between API modules - use TYPE_CHECKING for type hints
10. **Thread Safety**: Always use `ThreadSafeFileManager` methods with lock protection when accessing file information

### Performance Considerations

- The system is optimized for batch processing with high concurrency
- Model pooling reduces initialization overhead for repeated tasks  
- GPU acceleration is enabled for audio processing when available
- Memory limits prevent system overload on large servers

## ðŸ”„ Version Information

- **Current Version**: 3.1.6-FunASR
- **Architecture**: DDD with FunASR integration
- **Last Updated**: 2025-12-29
- **Python Version**: 3.8+
- **Framework**: FastAPI 0.120.4

### Recent Updates (v3.1.6-FunASR, 2025-12-29)

#### Configuration Simplification
- âœ… **Removed Environment Distinction**: Removed development/staging/production environment switching
  - `config.py` no longer loads different configs based on `ENVIRONMENT`
  - Docker config removed `ENVIRONMENT` variable
- âœ… **Simplified Config Loading**: Direct `load_dotenv()` without environment-based file selection
- âœ… **AI Model Config Optimization**: Added default API base URLs and model names for DeepSeek/Qwen/GLM

#### New Features
- âœ… **Hotword API Parameter**: Hotword can now be passed via API, falls back to config.py if not provided
- âœ… **Audio Preprocessing**: Auto-convert uploaded audio to 16kHz WAV for better performance
- âœ… **Meeting Summary Outline**: Added "å¤§çº²" (outline) field to meeting summary template

#### Code Cleanup
- âœ… **Removed Hotword Management API**: Deleted `GET/POST/DELETE /api/voice/hotwords` endpoints
- âœ… **Simplified TextProcessor**: Removed synonym config file loading, using built-in mappings

#### Technical Improvements
- âœ… Optimized `audio_processor.py`: Added format check, skip FFmpeg for pre-processed files
- âœ… Added `preprocess_audio_to_16khz` method to `storage.py`
- âœ… Simplified concurrency config: Removed environment-based switching

### Previous Updates (v3.1.5-FunASR, 2025-12-24)

#### Health Check & Docker Configuration Fixes
- âœ… **Health Check Field Name Fix**: Fixed model pool stats field name mismatch (`available_count` and `current_size`)
- âœ… **Lazy Loading Mode Optimization**: Model not loaded no longer affects health status
- âœ… **Dify Service Optional**: Dify Webhook is now optional and doesn't affect overall health status
- âœ… **Docker Environment Variable Fix**: Fixed `DIFY_BASE_URL` loading from `.env` file in Docker Compose
- âœ… **Health Check Configuration**: Optimized Docker health check parameters (interval: 1h, start_period: 120s)

### Previous Updates (v3.1.3-FunASR, 2025-12-04)

#### API Simplification
- âœ… **Removed One-Stop Transcription Interface**: Deleted `/api/voice/transcribe_all` endpoint
- âœ… **Removed Clear Dify Files Feature**: Deleted `_clear_dify` special operation
- âœ… **Enhanced Transcription API**: Improved `POST /api/voice/transcribe` with `wait=true` to return transcript directly without words field

### Previous Updates (v3.1.1-FunASR, 2025-11-13)

#### New Features
- âœ… **True Stop Transcription**: Implemented real task interruption using `_cancelled` flag and `InterruptedError` mechanism
- âœ… **Clear All History**: New endpoint `DELETE /api/voice/files/_clear_all` to clear all transcription history

#### Bug Fixes
- âœ… **Filename Uniqueness**: Fixed filename conflicts in batch transcription by using microsecond timestamps and `file_id`
- âœ… **Delete Stopped Files**: Fixed issue where stopped transcription files couldn't be deleted
- âœ… **WebSocket Progress Jump**: Fixed progress jumping issue, ensuring progress only increases
- âœ… **UI Update After Delete**: Fixed issue where UI didn't update immediately after file deletion
- âœ… **Delete Error Message**: Fixed incorrect "deletion failed" message when deleting stopped transcription files

#### Technical Improvements
- âœ… Improved cancellation mechanism using `cancellation_flag` to check cancellation status at key steps
- âœ… Optimized WebSocket message handling to prevent progress regression
- âœ… Improved error handling for file deletion, correctly parsing FastAPI HTTPException responses

## ðŸ“š Related Documentation

- [API Documentation](http://localhost:8998/docs) - Auto-generated FastAPI docs
- [README.md](README.md) - Complete project documentation and usage guide
- [ModelScope Models](https://modelscope.cn/) - AI model platform documentation
- [FunASR](https://github.com/alibaba-damo-academy/FunASR) - Speech recognition framework

---

This guide should provide Claude instances with the essential context needed to understand and work effectively with this audio transcription system. Always refer to the actual code files for the most current implementation details.
